ðŸ›• Temple of Diagnosis


---

My diagnosis:

Both training and validation RMSE steadily increase after a few epochs.

Explanation: The model initially learns (RMSE dips until about epoch 5), but then the optimizerâ€™s weights begin to overshoot minima in the loss landscape, causing both training and validation errors to climb thereafter.


---

Validation RMSE remains above training RMSE at every epoch.

Explanation: The validation set uses CDx/CDy and space values (e.g., WYâ€‰=â€‰WXÃ—{1,2,3}, spaceâ€‰=â€‰40â€“500) that fall outside or at the edges of the denser training grid. These novel combinations are harder to predict, so the modelâ€™s validation error stays higher than its training error.


---

Absolute trainâ€“val RMSE gap shrinks early, then increases as errors worsen.

Explanation: Early on, the model fits the training data faster than it generalizesâ€”narrowing the gap. But as both RMSEs climb due to unstable optimization, the numerical gap widens again, reflecting shared performance degradation rather than improved generalization.


---

Diagnosis:

The model exhibits training divergence after initial learning. Its RMSE rises for both train and validation sets, with validation error consistently higherâ€”indicative of unstable training dynamics (e.g., learning rate too high, insufficient regularization) and poor generalization to the sparser validation grid.

